{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO in class\n",
    "* install BeautifulSoup if you do not have it already\n",
    "* pip install beautifulsoup4 \n",
    "* note the 4 at the end\n",
    "* find two URLs that you want to scrape on SS.com\n",
    "* scrape the data from the first page\n",
    "* scrape the data from the second page\n",
    "* you can use the functions I provided in the class\n",
    "\n",
    "* save both as csv files\n",
    "* and make plot of the data - up to you what you want to plot\n",
    "\n",
    "\n",
    "* homework will be to try to srape date from some other site - such as wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.ss.com/en/animals/dogs/'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url1 = \"https://www.ss.com/en/animals/dogs/\"\n",
    "url1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.ss.com/en/electronics/computers/pc/'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url2 = \"https://www.ss.com/en/electronics/computers/pc/\"\n",
    "url2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req = requests.get(\"https://www.ss.com/en/animals/dogs/\") # so here we make a call to webpage via HTTP GET request and get something back\n",
    "req.status_code # we could add if to check for 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>SS.COM Animals - Dogs, puppies, Prices - Advertisements</title>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(req.text, 'lxml') \n",
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets combine the above cells into a function which will always get us columns\n",
    "def getColList(soup):\n",
    "    column_list = [\"description\",\"url\"] # we decided to that we need these two column names no matter the html\n",
    "    headline = soup.find(\"tr\", {\"id\":\"head_line\"})\n",
    "    headtds = headline.find_all(\"td\")\n",
    "    headcolumns = [el.text for el in headtds[1:]] # this will get all column names starting with 2nd in HTML\n",
    "    column_list += headcolumns\n",
    "    return column_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['description', 'url', 'Breed', 'Age', 'Price']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = getColList(soup)\n",
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRowList(soup):\n",
    "    trows = soup.find_all('tr')\n",
    "    aprows = [row for row in trows if row.get('id',\"\").startswith(\"tr_\") and not row.get('id',\"\").startswith(\"tr_bnr\") ]\n",
    "    return aprows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRow(row,colist=column_names):\n",
    "    row_tds = row.find_all('td')\n",
    "    rowDict = {}\n",
    "    if len(row_tds) < 3: # a little sanity check\n",
    "        print(\"Hmm bad row\")\n",
    "        return rowDict\n",
    "    \n",
    "    rowDict[colist[0]] = row_tds[2].text # so the big assumption is that we always get description in 3rd column\n",
    "    rowDict[colist[1]] = \"https://ss.com\" + row_tds[1].find('a').get('href')\n",
    "    for td,key in zip(row_tds[3:],colist[2:]): \n",
    "        rowDict[key] = td.text\n",
    "    return rowDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRows(rowlist,colist=column_names):\n",
    "    return [getRow(row, colist=colist) for row in rowlist] # so return a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so with this function I can get full dataframe from a single page on ss.com not only apartments\n",
    "def getDFfromURL(url):\n",
    "    # print(\"getting data from\", url)\n",
    "    req = requests.get(url)\n",
    "    if req.status_code != 200:\n",
    "        print(\"Request Fail with\", req.status_code)\n",
    "        return None # maybe return empty dataframe here\n",
    "    soup = BeautifulSoup(req.text, 'lxml')\n",
    "    column_names = getColList(url)\n",
    "    rowlist = getRowList(url)\n",
    "    rows = getRows(rowlist,colist=column_names)\n",
    "    return pd.DataFrame(rows, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tr id=\"tr_52255531\"><td class=\"msga2 pp0\"><input id=\"c52255531\" name=\"mid[]\" type=\"checkbox\" value=\"52255531_14023_0\"/></td><td class=\"msga2\"><a href=\"/msg/en/animals/dogs/outbred/apxif.html\" id=\"im52255531\"><img alt=\"\" class=\"isfoto foto_list\" src=\"https://i.ss.com/gallery/5/997/249152/49830343.th2.jpg\"/></a></td><td class=\"msg2\"><div class=\"d1\"><a class=\"am\" data=\"JTk5ayU5QiU4MCU4Q2olREZpJTlBJTdCJTg5aSU5Q3ElOTYlODAlODVrJTk0byU5NHolODNmJTkz|c8dGS6\" href=\"/msg/en/animals/dogs/outbred/apxif.html\" id=\"dm_52255531\">Mamma Vācu aitu sugas, tēvs Haski. \n",
       "Labs sargs jūsu mājai un uzticams draugs. \n",
       "6 meite</a></div><div class=\"ads_region\">Ogre and reg.</div></td><td c=\"1\" class=\"msga2-o pp6\" nowrap=\"\">Outbred</td><td c=\"1\" class=\"msga2-o pp6\" nowrap=\"\">1.1 mon.</td><td c=\"1\" class=\"msga2-o pp6\" nowrap=\"\">50  €</td></tr>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apt_rows[0] # first row of ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'description': 'Предлагаются к резервированию щеночки мальтипу- все мальчики. Мама- мальтийская болонка,Jekabpils and reg.',\n",
       "  'url': 'https://ss.com/msg/en/animals/dogs/caniche-miniature/cxplgm.html',\n",
       "  'Breed': 'Caniche Miniature',\n",
       "  'Age': '0.5 mon.',\n",
       "  'Price': '950  €'},\n",
       " {'description': 'Silikona birste suņu un kaķu mazgāšanai dzeltena (5626_1)\\r\\n\\r\\nProdukta īpašības:\\r\\n IzgataRiga',\n",
       "  'url': 'https://ss.com/msg/en/animals/dogs/accessories/cxlkb.html',\n",
       "  'Breed': '-',\n",
       "  'Age': '-',\n",
       "  'Price': '3.50  €'},\n",
       " {'description': 'Предлагается мальчик йоркширского терьера, малыш активный, имеет евро паспорт, прививку Riga district',\n",
       "  'url': 'https://ss.com/msg/en/animals/dogs/yorkshire-terrier/emkfn.html',\n",
       "  'Breed': 'Yorkshire Terrier',\n",
       "  'Age': '2 mon.',\n",
       "  'Price': '600  €'}]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_ads = getRows(apt_rows)\n",
    "row_ads[-3:] # last 3 ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 5)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtemp = pd.DataFrame(row_ads, columns=column_names)\n",
    "dtemp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>Breed</th>\n",
       "      <th>Age</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mamma Vācu aitu sugas, tēvs Haski. \\r\\nLabs sa...</td>\n",
       "      <td>https://ss.com/msg/en/animals/dogs/outbred/apx...</td>\n",
       "      <td>Outbred</td>\n",
       "      <td>1.1 mon.</td>\n",
       "      <td>50  €</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Весёлый, ласковый мальчик ждёт любящую семью. ...</td>\n",
       "      <td>https://ss.com/msg/en/animals/dogs/caniche-min...</td>\n",
       "      <td>Caniche Miniature</td>\n",
       "      <td>3 mon.</td>\n",
       "      <td>700  €</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pēc mūsu 13 gadus vecā Labradora zaudēšana pag...</td>\n",
       "      <td>https://ss.com/msg/en/animals/dogs/labrador-re...</td>\n",
       "      <td>Labrador Retriever</td>\n",
       "      <td>3 mon.</td>\n",
       "      <td>buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nodosim mīļās, gādīgās, labās rokās mazos suņu...</td>\n",
       "      <td>https://ss.com/msg/en/animals/dogs/labrador-re...</td>\n",
       "      <td>Labrador Retriever</td>\n",
       "      <td>2 mon.</td>\n",
       "      <td>100  €</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Очаровательные, любознательные малыши ищут отв...</td>\n",
       "      <td>https://ss.com/msg/en/animals/dogs/outbred/cbe...</td>\n",
       "      <td>Outbred</td>\n",
       "      <td>3 mon.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  \\\n",
       "0  Mamma Vācu aitu sugas, tēvs Haski. \\r\\nLabs sa...   \n",
       "1  Весёлый, ласковый мальчик ждёт любящую семью. ...   \n",
       "2  Pēc mūsu 13 gadus vecā Labradora zaudēšana pag...   \n",
       "3  Nodosim mīļās, gādīgās, labās rokās mazos suņu...   \n",
       "4  Очаровательные, любознательные малыши ищут отв...   \n",
       "\n",
       "                                                 url               Breed  \\\n",
       "0  https://ss.com/msg/en/animals/dogs/outbred/apx...             Outbred   \n",
       "1  https://ss.com/msg/en/animals/dogs/caniche-min...   Caniche Miniature   \n",
       "2  https://ss.com/msg/en/animals/dogs/labrador-re...  Labrador Retriever   \n",
       "3  https://ss.com/msg/en/animals/dogs/labrador-re...  Labrador Retriever   \n",
       "4  https://ss.com/msg/en/animals/dogs/outbred/cbe...             Outbred   \n",
       "\n",
       "        Age   Price  \n",
       "0  1.1 mon.   50  €  \n",
       "1    3 mon.  700  €  \n",
       "2    3 mon.    buy   \n",
       "3    2 mon.  100  €  \n",
       "4    3 mon.       -  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtemp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtemp.to_excel(\"dogs_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "slice indices must be integers or None or have an __index__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [58], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m imanta \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhttps://www.ss.com/en/animals/dogs/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m idf \u001b[39m=\u001b[39m getDFfromURL(imanta)\n\u001b[1;32m      3\u001b[0m idf\u001b[39m.\u001b[39mhead()\n",
      "Cell \u001b[0;32mIn [47], line 9\u001b[0m, in \u001b[0;36mgetDFfromURL\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39m# maybe return empty dataframe here\u001b[39;00m\n\u001b[1;32m      8\u001b[0m soup \u001b[39m=\u001b[39m BeautifulSoup(req\u001b[39m.\u001b[39mtext, \u001b[39m'\u001b[39m\u001b[39mlxml\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m column_names \u001b[39m=\u001b[39m getColList(url)\n\u001b[1;32m     10\u001b[0m rowlist \u001b[39m=\u001b[39m getRowList(url)\n\u001b[1;32m     11\u001b[0m rows \u001b[39m=\u001b[39m getRows(rowlist,colist\u001b[39m=\u001b[39mcolumn_names)\n",
      "Cell \u001b[0;32mIn [41], line 4\u001b[0m, in \u001b[0;36mgetColList\u001b[0;34m(soup)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetColList\u001b[39m(soup):\n\u001b[1;32m      3\u001b[0m     column_list \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mdescription\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39murl\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m# we decided to that we need these two column names no matter the html\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     headline \u001b[39m=\u001b[39m soup\u001b[39m.\u001b[39;49mfind(\u001b[39m\"\u001b[39;49m\u001b[39mtr\u001b[39;49m\u001b[39m\"\u001b[39;49m, {\u001b[39m\"\u001b[39;49m\u001b[39mid\u001b[39;49m\u001b[39m\"\u001b[39;49m:\u001b[39m\"\u001b[39;49m\u001b[39mhead_line\u001b[39;49m\u001b[39m\"\u001b[39;49m})\n\u001b[1;32m      5\u001b[0m     headtds \u001b[39m=\u001b[39m headline\u001b[39m.\u001b[39mfind_all(\u001b[39m\"\u001b[39m\u001b[39mtd\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m     headcolumns \u001b[39m=\u001b[39m [el\u001b[39m.\u001b[39mtext \u001b[39mfor\u001b[39;00m el \u001b[39min\u001b[39;00m headtds[\u001b[39m1\u001b[39m:]] \u001b[39m# this will get all column names starting with 2nd in HTML\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: slice indices must be integers or None or have an __index__ method"
     ]
    }
   ],
   "source": [
    "imanta = \"https://www.ss.com/en/animals/dogs/\"\n",
    "idf = getDFfromURL(imanta)\n",
    "idf.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('myenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f4399fc022079f002860625cc5707f51dba9801f67dbcb5cf226f7f6d65ac101"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
